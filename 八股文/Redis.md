# Redis

## 认识Redis

### 什么是Redis

Redis是一种基于内存的数据库，对数据的读写操作都是在内存中完成的，因此读写速度非常快，常用于缓存，消息队列，分布式锁等场景。

Redis提供了多种数据类型来支持不同的业务场景，比如String（字符串）、Hash（哈希）、List（列表）、Set（集合）、ZSet（有序集合）、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是原子性的，因为执行命令是由单线程负责，不存在并发竞争的问题。

除此之外，Redis还支持事务、持久化、Lua脚本、多集群方案（主从复制、哨兵模式、切片机群模式）、发布/订阅模式、内存淘汰机制、过期删除机制等等。

### Redis和Memcached有什么区别？

很多人说用Redis作为缓存，但是Memcached也是基于内存的数据库，为什么不选择它作为缓存呢？

要解答这个问题，我们就要弄清楚Redis与Memcached的区别。Redis与Memcached共同点：

1. 都是基于内存的数据库，一般用来当做缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

Redis与Memcached的区别：

- Redis支持的数据类型更丰富（String、Hash、List、Set、ZSet），而Memcached只支持最简单的key-value数据类型；
- Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用，而Memcached没有持久化功能，数据全部存储在内存之中，Memcached重启或挂掉后，数据就没了；
- Redis原生支持集群模式，Memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；
- Redis支持发布订阅模式、Lua脚本、事务等功能，而Memcached不支持；

### 为什么用Redis作为MySQL的缓存？

主要是因为Redis具备`高性能`和`高并发`两种特性。

1. Redis具备高性能

   ​	加入用户第一次访问MySQL中的某些数据。这个过程会比较慢，因为是从硬盘读取的。将该用户访问的数据缓存在Redis中，这样下一次访问这些数据的时候就可以直接从缓存中获取了，操作Redis缓存就是直接操作内存，所以速度相当块。

   ​	如果MySQL中对应数据改变了之后，同步更改Redis缓存中相应的数据即可，不过这里会有Redis和MySQL双写一致性的问题，后面我们会提到。

2. Redis具备高并发

   ​	单台设备的Redis的QPS（Query Per Second，每秒钟处理完请求的次数）是MySQL的10倍，Redis单机的QPS能轻松破10W，而MySQL单机的QPS很难破1W。所以，直接访问Redis能够承受的最大请求远远大于直接访问MySQL的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。

## Redis数据结构

### Redis数据类型以及使用场景分别是什么？

Redis提供了丰富的数据类型，常见的五种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合），ZSet（有序集合）。

| 结构类型     | 结构存储的值                               | 结构的读写能力                                               |
| ------------ | ------------------------------------------ | ------------------------------------------------------------ |
| String字符串 | 可以是字符串、整数或浮点数                 | 对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作； |
| List列表     | 一个链表，链表上的每个节点都包含一个字符串 | 对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素 |
| Set集合      | 包含字符串的无序集合                       | 字符串的集合，包含基础的方法有看是否存在添加、获取、删除；还包含计算交集、并集、差集等 |
| Hash散列     | 包含键值对的无序列表                       | 包含方法有添加、获取、删除单个元素                           |
| Zet有序集合  | 和散列一样，用于存储键值对                 | 字符串成员与浮点数分数之间的有序映射；元素的排序顺序由分数的大小决定；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素 |

随着Redis版本的更新，后面又支持了四种数据类型：BitMap（2.2版新增）、HyperLogLog（2.8版新增）、GEO（3.2版新增）、Stream（5.0版新增）。Redis五种基本数据类型的应用场景：

- String类型的应用场景：缓存对象、常规技术、分布式锁、共享session信息等。
- List类型的应用场景：消息队列（但有两个问题：1.生产者需自行实现全局唯一ID；2.不能以消费组形式消费数据）等。
- Hash类型：缓存对象、购物车等。
- Set类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
- ZSet类型：排序场景，比如说排行榜、电话和姓名排序等。

Redis后续版本又支持四种数据类型，它们的应用场景如下：

- BitMap（2.2版新增）：二值状态统计的场景，比如签到、判断用户登录状态、连续签到用户总数等；
- HyperLogLog（2.8版新增）：海量数据基数统计的场景，比如百万级页面UV技术等；
- GEO（3.2版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0版新增）：消息队列，相比于基于List类型实现的消息队列，有这两个特有的特征：自动生成全局唯一消息ID，支持以消费组形式消费数据。

### 五种常见的Redis数据类型是怎么实现的？

#### String类型内部实现

String类型的底层的数据结构实现主要是SDS（简单动态字符串）。SDS和我们认识的C字符串不大一样，之所以没有使用C语言的字符串表示，因为SDS	相比于C的原生字符串：

- SDS不仅可以保存文本数据，还可以保存二进制数据。因为SDS使用len属性的值而不是空字符来判断字符串是否结束，而且SDS的所有API都会以处理二进制的方式来处理SDS存放在buf[]数组里的数据。所以SDS不光能存放文本数据，而且还保存图片、音频、视频、压缩文件这样的二进制数据。
- SDS获取字符串长度的时间复杂度是O（1）。因为C语言的字符串并不记录自身长度，所以获取长度的复杂度为O（n）；而SDS结构里用len属性记录了字符串长度，所以复杂度为O（1）。
- Redis的SDS API是安全的，拼接字符串不会造成缓冲区溢出。因为SDS在拼接字符串之前会检查SDS空间是否满足要求，如果空间不够会自动扩容，所以不回导致缓冲区溢出的问题。

#### List类型内部实现

list类型底层数据结构是由双向链表或压缩列表实现的：

- 如果列表的元素个数小于512个（默认值，可由list-max-ziplist-entries配置），列表每个元素的值都小于64字节（默认值，可由list-max-ziplist-value配置），Redis会使用压缩列表作为List类型的底层数据结构；
- 如果列表的元素不满足上面的条件，Redis会使用双向链表作为List类型的底层数据结构；

但是在Redis3.2版本之后，List数据类型底层数据结构就只由quicklist实现了，代替了双向链表和压缩列表。

#### Hash类型内部实现

Hash类型的底层数据结构是由压缩列表或哈希表实现的：

- 如果哈希类型元素个数小于512个（默认值，可由hash-maxziplist-entries配置），所有值小于64字节（默认值，可有hash-max_ziplist-value配置）的话，Redis会使用压缩列表作为Hash类型的底层数据结构；
- 如果哈希类型元素不满足上面条件，Redis会使用哈希表作为Hash类型的底层数据结构。

在Redis7.0中，压缩列表数据结构已经废弃了，交由listpack数据结构来实现。

#### Set类型内部实现

Set类型的底层数据结构是由哈希表或证书集合实现的：

- 如果集合中的元素都是整数且元素个数小于512（默认值，set-maxinset-entries配置）个，Redis会使用整数集合作为Set类型的底层数据结构；
- 如果集合中的元素不满足上面条件，则Redis使用哈希表作为Set类型的底层数据结构。

#### ZSet类型内部实现

ZSet类型的底层数据结构是由压缩列表或跳表实现的：

- 如果有序结合的元素个数小于128个，并且每个元素的值小于64字节时，Redis会使用压缩列表作为ZSet类型的底层数据结构；
- 如果有序集合的元素不满足上面的条件，Redis会使用跳表作为ZSet类型的底层数据结构；

在Redis7.0中，压缩列表数据结构已经废弃，交由listpack数据结构来实现。

## Redis线程模型

### Redis是单线程吗？

Redis单线程指的时`接收客户端请求->解析请求->进行数据读写等操作->发送数据给客户端`这个过程是由一个线程（主线程）来完成的额，这也是我们常说Redis时单线程的原因。

但是，Redis程序并不是单线程的，Redis在启动的时候，是会启动后台线程（BIO）的：

- Redis在2.6版本，会启动2个后台线程，分别处理关闭文件、AOF刷盘这两个任务；
- Redis在4.0版本之后，新增了一个新的后台线程，用来异步释放Redis内存，也就是lazyfree线程。例如执行unlink key /flushdb async /flushall async等命令，会把这些删除操作交给后台线程来执行，好处是不会导致Redis主线程卡顿。因此，我们要删除一个大key的时候，不要使用del命令删除，因为del是在主线程处理的，这样会导致Redis主线程卡顿，因此我们应该使用unlink命令来异步删除大key。



之所以Redis为`关闭文件、AOF刷盘、释放内存`这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么Redis主线程就很容易发生阻塞，这样就无法处理后续的请求了。

后台线程相当于一个消费者，生产者把耗时任务丢进任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行相应的方法即可。



关闭并文件、AOF刷盘、释放内存这三个任务都有各自的任务队列：

- BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用close(fd)，将文件关闭；
- BIO_AOF_FSYNC，AOF刷盘任务队列：当AOF日志配置成everysec选项后，主线程会把AOF写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用fsync(fd)，将AOF文件刷盘；
- BIO_LAZY_FREE，lazy free任务队列：当队列有任务后，后台线程会free(obj)释放对象/free(dict)删除数据库所有对象/free(skiplist)释放跳表对象；

### Redis单线程模式是怎样的？

Redis6.0版本之前，网络和IO命令处理都是单线程的。Redis初始化的时候，会做下面这几件事情：

- 首先，先调用处理发送队列函数，看发送队列里是否有任务，如果有发送任务，则通过write函数将客户端发送缓冲区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待epoll_wait发现可写后再处理。

- 接着，调用epoll_wait函数等待事件的到来：

  - 如果是连接事件的到来，则会调用连接事件处理函数，该函数会做这些事情：调用accept获取已连接的socket->调用epoll_ctl将已连接的socket加入到epoll->注册读事件处理函数；
  - 如果是读事件到来，则会调用读事件处理函数，该函数会做这些事情：调用read获取客户端发送的数据->解析命令->处理命令->将客户端对象添加到发送队列->将执行结果写到发送缓冲区等待发送；
  - 如果是写事件到来，则会调用写事件处理函数，该函数会做这些事情：通过write函数将客户端发送缓冲区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待epoll_wait发现可写后再处理。

以上就是Redis单线程模式的工作方式。

### Redis采用单线程会什么还这么快？

官方使用基准测试的结果是，单线程的Redis吞吐量可以达到10W/每秒。

之所以Redis采用单线程（网络/IO和执行命令）那么快，有如下几个原因：

- Redis的大部分操作都在内存中完成，并且采用了高效的数据结构，因此Redis瓶颈可能是机器的内存或网络带宽，而并非CPU，既然CPU不是瓶颈，那么自然就采用单线程的解决方案了；
- Redis采用单线程模式可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题；
- Redis采用了I/O多路复用机制处理大量的客户端Socket请求，IO多路复用机制是指一个线程处理多个IO流，，就是我们经常听到的select/epoll机制。简单来说，在Redis只运行单线程的情况下，该机制允许内核中，同时存在多个监听Socket和已连接的Socket。内核会一直监听这些Socket上的连接请求或数据请求。一旦有请求到达，就会交给Redis线程处理，这就实现了一个Redis线程处理多个IO流的效果。

### Redis6.0之前为什么使用单线程？

我们都知道单线程的程序是无法利用服务器的多核CPU的，那么早期Redis版本的主要工作（网络I/O和执行命令）为什么还要使用单线程呢？

官方回答：CPU并不是制约Redis性能表现得瓶颈所在，更多情况下是受到内存大小和网络I/O得限制，所以Redis核心网络模型使用单线程并没有什么问题，如果你想要使用服务的多核CPU，可以在一台服务器上启动多个节点或采用分片集群的方式。

除了上面的官方回答，选择单线程的原因也有下面的考虑。

使用了单线程后，可维护性高，多线程模式虽然在某些方面表现优异，但它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。

### Redis6.0之后为什么引入了多线程？

虽然Redis的主要工作（网络I/O和执行命令）一直是单线程模型，但是在Redis6.0版本之后，也采用了多个I/O线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis的性能瓶颈有时会出现在网络I/O的处理上。

所以为了提高网络I/O的并行度，Redis6.0对于网络I/O采用多线程来处理。但是对于命令的执行，Redis仍然使用单线程来处理，所以大家不要误解Redis有多线程同时执行命令。

Redis官方表示，Redis6.0版本引入的多线程I/O特性对性能提升至少是一倍以上。

Redis6.0版本支持的I/O多线程特性，默认情况下I/O多线程只针对发送响应数据（write client socket），并不会以多线程的方式处理读请求（read client socket）。要想开启多线程处理客户端请求，就需要吧Redis.conf配置文件中的`io-thread-do-reads`配置项设为yes。同时，Redis.conf配置文件中提供了多线程个数的配置项`io-threads`。

关于线程的设置，官方的建议是如果为4核的CPU，建议线程数设置为2或3，如果为8核CPU建议线程数设置为6，线程数一定要小于机器核数，线程数并不是越大越好。

因此，Redis6.0版本之后，Redis在启动的时候，默认情况下会创建额外的6个线程（这里的线程不包括主线程）：

- Redis-server: Redis的主线程，主要负责执行命令；
- bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件系统任务、AOF刷盘任务、释放内存任务；
- io_thd_1、io_thd_2、io_thd_3：三个I/O线程，io_threads默认是4，所以会启动3（4-1）个I/O多线程，用来分担Redis网络I/O的压力。

## Redis持久化

### Redis如何实现数据不丢失？

Redis的读写操作都是在内存中，所以Redis性能才会高，但是当Redis重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在Redis重启后就能够从磁盘中恢复原有的数据。

Redis共有三种数据持久化的方式：

- AOF日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；
- RDB快照：将某一时刻的内存数据，以二进制的方式写入磁盘；
- 混合持久化方式：Redis4.0增加的方式，集成了AOF和RDB的优点；

### AOF日志是如何实现的？

Redis在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后Redis重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。

#### 为什么先执行命令，再把数据写入日志呢？

Redis是先执行写操作命令后，才将该命令记录到AOF日志里，这么做其实有两个好处。

- 避免额外的检查开销：因为如果先将写操作命令记录到AOF日志里，再执行命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到AOF日志里后，Redis在使用日志恢复数据时，就可能会出错。
- 不会阻塞当前写操作命令的执行：因为当写操作命令执行成功后，才会将命令记录到AOF日志。

当然，这样做也会带来风险：

- 数据可能会丢失：执行写操作命令和记录日志是两个过程，那么当Redis在还没来记得将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。
- 可能阻塞其他操作：由于写操作命令执行成功后才记录到AOF日志，所以不会阻塞当前命令的执行，但因为AOF日志也是在主线程中执行的，所以当Redis把日志文件写入到磁盘的时候，还是会阻塞后续的操作无法执行。

#### AOF写回策略有几种？

Redis写入AOF日志的过程：

1. Redis执行完写操作命令后，会将命令追加到server.aof_buf缓冲区；
2. 然后通过write()系统调用，将aof_buf缓冲区的数据写入到AOF文件，此时数据并没有写入到硬盘。而是拷贝到了内核缓冲区page cache，等待内核将数据写入硬盘；
3. 具体内核缓冲区的数据什么时候写入硬盘，由内核决定。

Redis提供了3种写回硬盘的策略，控制的就是上面说的第三步过程。在Redis.conf配置文件的appendfsync配置项可以有以下3种参数可填：

- Always，这个单词的意思是`总是`，所以它的意思时每次写操作命令执行完后，同步将AOF日志数据写回硬盘；
- Everysec，这个单词的意思是`每秒`，所以它的意思是每次写操作命令执行完后，先将命令写入到AOF文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；
- No，意味着不由Redis控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到AOF文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。

| 写回策略 | 写回时机           | 优点                             | 缺点                               |
| -------- | ------------------ | -------------------------------- | ---------------------------------- |
| Always   | 同步写回           | 可靠性高、最大程度保证数据不丢失 | 每个写命令都要写回硬盘，性能开销大 |
| Everysec | 每秒写回           | 性能适中                         | 宕机时会丢失1秒内的数据            |
| No       | 由操作系统控制写回 | 性能好                           | 宕机时丢失的数据可能会更多         |

#### AOF日志过大，会触发什么机制？

AOF日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。如果当AOF日志文件过大就会带来性能问题，比如重启Redis后，需要读AOF文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。

所以，Redis为了避免AOF文件越写越大，提供了AOF`重写机制`，来压缩AOF文件。

AOF重写机制是在重写时，读取当前数据库中所有键值对，然后将每一个键值对用一条命令记录到`新的AOF文件`，等到全部记录完后，就将新的AOF文件替换掉现有的AOF文件。

举个例子，在没有重写机制前，假设前后执行了`set name xiaolin`和`set name xiaolincoding`这两个命令的话，就会将这两个命令记录到AOF文件。

但是在重写机制后，就会读取name最新的value（键值对），然后用一条`set name xiaolincoding`命令记录到新的AOF文件，之前的第一个命令就没有必要记录了，因为它属于历史命令，没有作用了。这样依赖，一个键值对在重写日志中只用一条命令就行了。

重写工作完成后，就会将新的AOF文件覆盖现有的AOF文件，这就相当于压缩了AOF文件，使得AOF文件体积变小了。

#### 重写AOF日志的过程是怎样的？

Redis的重写AOF过程是由后台子进程bgrewriteaof来完成的，这么做可以达到两个好处：

- 子进程进行AOF重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；
- 子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生`写时复制`，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。

触发重写机制后，主进程就会创建重写AOF的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写AOF子进程会读取数据库的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志。（新的AOF文件）。

但是重写过程中，主进程依然可以正常处理命令，那么问题来了，重写AOF日志过程中，如果主进程修改了已经存在的key-value，那么会发生写时复制，此时这个key-value数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？

为了解决这种数据不一致问题，Redis设置了一个AOF重写缓冲区，这个缓冲区在创建bgwriteaof子进程之后开始使用。

在重写AOF期间，当Redis执行完一个写命令之后，它会同时将这个写命令写入到`AOF缓存区`和`AOF重写缓冲区`。

也就是说，在bgrewriteaof子进程执行AOF重写期间，主进程需要执行以下三个工作：

- 执行客户端发来的命令；
- 将执行后的写命令追加到`AOF缓冲区`；
- 将执行后的写命令追加到`AOF重写缓冲区`；

当子进程完成AOF重写工作（扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志）后，会向主进程发送一条信号，信号时进程间通讯的一种方式，且时异步的。

主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：

- 将AOF重写缓冲区中的所有内容追加到新的AOF文件中，使得新旧两个AOF文件所保存的数据库状态一致；
- 将新的AOF文件进行改名，覆盖现有的AOF文件。

信号函数执行完后，主进程就可以继续像往常一样处理命令了。

### RDB快照是如何实现的呢？

因为AOF日志记录的时操作命令，不是实际的数据，所以用AOF方法做故障恢复时，需要全量把日志都执行一遍，一旦AOF日志非常多，势必会造成Redis的恢复操作缓慢。

为了解决这个问题，Redis增加了RDB快照。所谓的快照，就是记录某一个瞬间的东西，比如当我们给风景拍照时，那一瞬间的画面和信息就记录到了一张照片。

所以，RDB快照就是记录某一个瞬间的内存数据，记录的是实际数据，而AOF文件记录的是命令的操作日志，而不是实际的数据。

因此在Redis恢复数据时，RDB恢复数据的效率会比AOF高些，因为直接将RDB文件读入内存就可以，不需要像AOF那样还需要额外执行操作命令的步骤才能恢复数据。

#### RDB做快照时会阻塞线程吗？

Redis提供了两个命令来生成RDB文件，分别时save和bgsave，它们的区别就在于是否在`主线程`里执行：

- 执行save命令，就会在主线程生成RDB文件，由于和执行操作命令在同一个线程，所以如果写入RDB文件的时间太长，会阻塞线程；
- 执行了bgsave命令，会创建一个子进程来生成RDB文件，这样可以避免主线程的阻塞；

Redis还可以通过配置文件的选项来实现每隔一段时间自动执行一次bgsave命令，默认会提供以下配置:

```shell
save 900 1
save 300 10
save 60 10000
```

别看选项名叫save，实际上执行的时bgsave命令，也就是会创建子进程来生成RDB快照文件。只需满足上面条件的任意一个，就会执行bgsave，它们的意思分别是：

- 900秒之内，对数据库进行了至少一次修改；
- 300秒之内，对数据库进行了至少10次修改；
- 60秒之内，对数据库进行了至少10000次修改；

这里提一点，Redis的快照时全量快照，也就是说每次执行快照，都是会把内存中的`所有数据`都记录到磁盘中。所以执行快照是一个比较重的操作，如果频率太频繁，可能会对Redis性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。

#### RDB在执行快照的时候，数据能修改吗？

可以的，执行bgsave过程中，Redis依然可以继续处理操作命令的，也就是数据是能被修改的，关键的技术就在于写时复制技术（Copy-On-Write，COW）。

执行bgsave命令的时候，会通过fork()创建子进程，此时子进程和父进程是共享同一片数据内存的，因为创建子进程的时候，会复制父进程的页表，但页表指向的物理内存还是一个，此时如果主进程执行读操作，则主进程和bgsave子进程相互不影响。

如果主进程执行写操作，则被修改的数据会复制一份副本，然后bgsave子进程会把该副本数据写入RDB文件，在这个过程中，主进程仍然可以直接修改原来的数据。

### 为什么会有混合持久化？

RDB优点是数据恢复时间快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。

AOF有点是丢失数据少，但是数据恢复不快。

为了集成两者的有点，Redis4.0提出了混合使用AOF日志和内存快照，也叫混合持久化，即保证了Redis重启速度，又降低数据丢失风险。

混合持久化工作在AOF日志重写过程中，当开启了混合持久化时，在AOF重写日志时，fork出来的重写子进程会先将于主线程共享的内存数据以RDB方式写入到AOF文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以AOF方式写入到AOF文件，写入完成后通知主进程将新的含有RDB格式和AOF格式的AOF文件替换旧的AOF文件。

也就是说，使用了混合持久化，AOF文件的前半部分时RDB格式的全量数据，后半部分时AOF格式的增量数据。

这样做的好处在于，重启Redis加载数据的时候，由于前半部分是RDB内容，这样加载的时候速度会很快。

加载完RDB的内容后，才会加载后半部分的AOF内容，这里的内容是Redis后台子进程重写AOF期间，主线程处理的操作命令，可以使得数据更少的丢失。

**混合持久化优点：**

- 混合持久化结合了RDB和AOF持久化的优点，开头为RDB的格式，使得Redis可以更快的启动，同时结合AOF的优点，又减少了大量数据丢失的风险。

**混合持久化缺点：**

- AOF文件中添加了RDB格式的内容，使得AOF文件的可读性变得很差；
- 兼容性差，如果开启混合持久化，那么混合持久化AOF文件，就不能再Redis4.0之前版本使用了。

## Redis集群

### Redis如何实现服务高可用？

要想设计一个高可用的Redis服务，一定要从Redis的多服务节点来考虑，比如Redis的主从复制、哨兵模式、切片集群。

#### 主从复制

主从复制是Redis高可用服务的最基础的保证，实现方案就是将从前的一台Redis服务器，同步数据到多台从Redis服务器上，即一主多从的模式，且主从服务器之间采用的是`读写分离`的方式。

主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。

也就是说，所有的数据修改只在主服务器上进行，然后将最近的数据同步给从服务器，这样就使得主从服务器的数据是一致的。

注意，主从服务器之间的命令复制时`异步`进行的。

具体来说，在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器的数据就不一致了。

所以，无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致时难以避免的。

#### 哨兵模式

在使用Redis主从服务的时候，会有一个问题，就是当Redis的主从服务器出现故障宕机时，需要手动进行恢复。

为了解决这个问题，Redis增加了哨兵模式（Redis Sentinel），因为哨兵模式做到了可以监控主从服务器，并且提供主从节点故障转移的功能。

#### 切片集群模式

当Redis缓存数据量大到一台服务器无法缓存时，就需要使用Redis切片集群（Redis Cluster）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高Redis服务器的读写性能。

Redis Cluster方案采用哈希槽（Hash Sot），来处理数据和节点之间的映射关系。在Redis Cluster方案中，一个切片集群共有16384个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的key，被映射到一个哈希槽中，具体执行过程分为两大步：

- 根据键值对的key，按照CRC16算法计算一个16bit的值；
- 再用16bit值对16384取模，得到0~16383范围内的模数，每个模数代表一个相应编号的哈希槽。

接下来的问题就是，这些哈希槽怎么被映射到具体的Redis节点上呢？有两种方案：

- 平均分配：在使用cluster create命令创建Redis集群时，Redis会自动把所有哈希槽平均分布到集群节点上。比如集群中有9个节点，则每个节点上槽的个数位16384/9个。
- 手动分配：可以使用cluster meet命令手动建立节点间的连接，组成集群，再使用cluster addslots命令，指定每个节点上的哈希槽个数。

假设切片集群一共有2个节点，共有4个哈希槽（Slot0~Slot3）时，我们就可以通过命令手动分配哈希槽，比如节点1保存哈希槽0和1，节点2保存哈希槽2和3.

```shell
redis-cli -h 192.168.1.10 -p 6379 cluster addslots 0,1
redis-cli -h 192.168.1.11 -p 6379 cluster addslots 2,3
```

然后再集群运行的过程中，key1和key2计算完CRC16值后，对哈希槽总个数4进行取模，再根据鸽子的模数结果，就可以被映射到哈希槽1（对应节点1）和哈希槽2（对应节点2）。

需要注意的是，再手动分配哈希槽时，需要把16384个槽都分配完，否则Redis集群无法正常工作。

### 集群脑裂导致数据丢失怎么办？

#### 什么是脑裂？

先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？

那么在Redis中，集群脑裂产生数据丢失的现象是怎样的呢？

在Redis主从架构中，部署方式一般是`一主多从`，主节点提供写操作，从节点提供读操作。如果主节点的网络突然发生了问题，它与所有的节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道Redis内部已经出现问题了，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。

这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在`从节点`中选举出一个leader作为主节点，这时集群就有两个主节点了——脑裂出现了。

然后，网络突然号了，哨兵因为之前已经选举出一个新主节点了，他就会把旧主节点降级位从节点（A），然后从节点（A）会向新主节点请求数据同步，因为第一次数据同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端再过程A写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题。

总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级位从节点，再与新主节点进行同步复制的时候，由于从节点会清空自己的缓冲区，所有导致之前客户端写入的数据丢失了。

#### 解决方案

当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。

在Redis的配置文件中有两个参数我们可以设置：

- min-slaves-to-write x，主节点必须要有至少x个从节点连接，如果小于这个数，主节点会禁止写数据。
- min-slaves-max-lag x，主从数据复制和同步的延迟不能超过x秒，如果超过，主节点会禁止写数据。

我们可以把min-slaves-to-write和min-slaves-max-lag这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设位N和T。

这两个配置项组合后的要求是，主库连接的从库至少有N个从库，和主库镜像数据复制时的ACK消息延迟不能超过T秒，否则，主库就不会再接受客户端的写请求了。

即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行ACK确认了。这样一来，min-slaves-to-write和min-slaves-max-lag的组合要求就无法得到满足，原主库就会被限制接受客户端写请求，客户端也就不能在原主库中写入新数据了。

等到新主库上线时，就只有新主库能接受和处理客户端请求，此时，新写的数据会被直接写入到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。

再来举个例子。

假设我们将min-slaves-to-write设置为1，把min-slaves-max-lag设置为12s，把哨兵的down-after-milliseconds设置为10s，主库因为某些原因卡住了15s，导致哨兵判断主库客观下线，开始进行主从切换。

同时因为原主库卡住了15s，没有一个从库能和主库在12s内进行数据复制，原主库也无法接受客户端请求了。

这样一来，主从切换完成后，也只有新主库能接受请求了，不会发生脑裂，也就不会发生数据丢失的问题了。

## Redis过期删除与内存淘汰

### Redis使用的过期删除策略是什么？

Redis是可以对key设置过期时间的，因此需要有响应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。

每当我们对一个key设置了过期时间时，Redis会把该key带上过期时间存储到一个过期字典（expires dict）中，也就是说`过期字典`保存了数据库中所有key的过期时间。

当我们查询一个key时，Redis首先检查该key是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该key的过期时间，然后与当前系统时间进行对比，如果比系统时间大，那就没有过期，否则判定该key已过期。

Redis使用的过期删除策略是`惰性删除+定期删除`这两种策略配合使用。

#### 什么是惰性删除策略？

惰性删除策略的做法是，不主动删除过期键，每次从数据库访问key时，都检测key是否过期，如果过期则删除该key。

惰性删除策略的优点：

- 每次访问时，才会检查key是否过期，所以次策略只会使用很少的系统资源，因此，惰性删除策略对CPU时间最友好。

惰性删除策略的缺点：

- 如果一个key已经过期，而这个key又仍然保留在数据库中，那么只要这个过期key一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以惰性删除策略对内存不友好。

#### 什么是定期删除策略？

定期删除策略的做法是，每隔一段时间`随机`从数据库中取出一定数量的key进行检查，并删除其中的过期key。

Redis的定期删除流程：

1. 从过期字典中随机抽取20个key；
2. 检查这20个key是否过期，并删除已过期的key；
3. 如果本轮检查的已过期key的数量，超过5个（20/4），也就是`已过期key的数量`占比`随机抽取key的数量`大于25%，则继续重复步骤1；如果已过期的key的比例小于25%，则停止继续删除过期key，然后等待下一轮再检查。

可以看到，定期删除是一个循环的过程。Redis为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环的时间上限，默认不回超过25ms。

定期删除策略的优点：

- 通过限制删除操作执行的时长和频率，来减少删除操作对CPU的影响，同时也能删除一部分的过期数据以减少过期键对空间的无效占用。

定期删除策略的缺点：

- 难以确定删除操作执行的时长和频率，如果执行的太频繁，就会对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期key占用的内存不会及时得到释放。

可以看到，惰性删除策略和定期删除策略都有各自的优点，所以Redis选择`惰性删除+定期删除`这两种策略配合使用，以求再合理使用CPU时间和避免内存浪费之间取得平衡。

### Redis持久化时，对过期键会如何处理的？

Redis持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File），下面我们分别来看过期键再这两种格式中呈现的状态。

**RDB文件分为两个阶段，RDB文件生成阶段和加载阶段。**

- RDB文件生成阶段：从内存状态持久化到RDB（文件）的时候，会对key进行过期检查，过期的键不会被保存到新的RDB文件中，因此Redis中的过期键不会对新生成RDB文件产生任何影响。
- RDB加载阶段：RDB加载阶段，要看服务器是主服务器还是从服务器，分别对应以下两种情况：
  - 如果Redis是主服务器运行模式的话，在载入RDB文件时，程序会对文件中保存的键进行检查，过期键不会被载入到数据库中。所以过期键不会对载入RDB文件的主服务器造成影响；
  - 如果Redis是从服务器运行模式的话，在载入RDB文件时，无论键是否过期都会被载入到数据库中。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入RDB文件的从服务器也不会造成影响。

**AOF文件分为两个阶段，AOF文件写入阶段和AOF重写阶段。**

- AOF文件写入阶段：当Redis以AOF模式持久化时，如果数据库某个过期键还没有被删除，那么AOF文件会保留次过期键，当此过期键被删除后，Redis会向AOF文件追加一条DEL命令来显式地删除该键值。
- AOF重写阶段：执行AOF重写时，会对Redis中地键值进行检查，已过期地键不会被保存到重写后的AOF文件中，因此不会对AOF重写造成任何影响。

### Redis主从模式中，对过期键会如何处理？

当Redis运行在主从模式下时，从库不会进行过期扫描，从库对过期的处理是被动的。也就是即使从库中的key过期了，如果有客户端访问从库时，依然可以得到key的值，像未过期的键值对一样返回。

从库的过期键处理依靠主服务器控制，主库在key到期时，会在AOF文件里增加一条del指令，同步到所有的从库，从库通过执行这条del指令来删除过期的key。

### Redis内存满了，会发生什么？

在Redis的运行内存达到了某个阈值，就会出发内存淘汰机制，这个阈值就是我们设置的最大运行内存，此值在Redis的配置文件中可以找到，配置项为maxmemory。

### Redis内存淘汰策略有哪些？

Redis内存淘汰策略共有八种，这八种策略大体分为`不进行数据淘汰`和`进行数据淘汰`两类策略。

1、不进行数据淘汰的策略

noeviction（Redis3.0之后，默认的内存淘汰策略）：它表示当前运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。

2、进行数据淘汰的策略

针对`进行数据淘汰`这一类策略，又可以细分为`在设置了过期时间的数据中进行淘汰`和`在所有数据范围内进行淘汰`这两类策略。

在设置了过期时间的数据进行淘汰：

- volatile-random：随机淘汰设置了过期时间的任意键值；
- volatile-ttl：优先淘汰更早过期的键值；
- volatile-lru（Redis3.0之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
- volatile-lfu（Redis4.0后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；

在所有数据范围内进行淘汰：

- allkeys-random：随即淘汰任意值；
- allkeys-lru：淘汰整个键值中最久未使用的键值；
- allkeys-lfu（Redis4.0后新增的内存淘汰策略）：淘汰整个简直中最少使用的键值。

### LRU算法和LFU算法有什么区别？

#### 什么是LRU算法？

LRU全称是Least Recent Used翻译为最近最少使用，会选择淘汰最近最少使用的数据。

传统LRU算法的实现是基于`链表`结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。

Redis并没有使用这样的方式实现LRU算法，因为传统的LRU算法存在两个问题：

- 需要用链表管理所有的缓存数据，这会带来额外的空间开销；
- 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来更多链表移动操作，很耗时，进而降低Redis缓存性能。

#### Redis是如何实现LRU算法的？

Redis实现的是一种近似LRU算法，目的时为了更好的节约内存，它的实现方式是在Redis的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。

当Redis进行内存淘汰时，会使用随机采样的方式来淘汰数据，它是随机取5个值（此值可配置），然后淘汰最久没有使用的那个。

Redis实现LRU算法的优点：

- 不用为所有的数据维护一个大链表，节省了空间占用；
- 不用在每次数据访问时都移动链表项，提升了缓存的性能；

但是LRU算法有一个问题，无法解决缓存污染问题，比如应用一次读取了大量的数据，而这些数据只会被读取一次，那么这些数据会留存在Redis缓存中很长一段时间，造成缓存污染。

因此，在Redis4.0之后引入了LFU算法来解决这个问题。

#### 什么是LFU算法？

LFU全称是Least Frequently Used翻译为最久不常使用的，LFU算法是根据数据访问次数来淘汰数据的，它的核心思想是”如果数据过去被访问多次，那么将来被访问的频率也会更高“。

所以，LFU算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于LRU算法也更合理一些。

#### Redis是如何实现LFU算法的？

LFU算法相比于LRU算法的实现，多记录了`数据的访问频次`的信息。Redis对象的结构如下：

```c
typedef struct redisObject {
    ...
        
    // 24 bits，用于记录对象的访问信息
    unsigned lru:24;
    ...
} robj
```

Redis对象头中的lru字段，在LRU算法下和LFU算法下使用方式并不相同。

**在LRU算法中**，Redis对象头的24bit的lru字符是用来记录key的访问时间戳，因此在LRU模式下，Redis可以根据对象头中的lru字段记录的值，来比较最后一次key的访问时间长，从而淘汰最久未被使用的key。

**在LFU算法中**，Redis对象头的24bits的lru字段被分成两端来存储，高16bit存储ldt（Last Decrement Time），用来记录key的访问时间戳；低8bit存储logc（Logistic Counter），用来记录key的访问频次。

## Redis缓存设计

## Redis 实战

